DR[flag == TRUE,`:=` (final_assembly1=final_assembly2,final_assembly2="",source_E1 = source_E2,source_E2="")]
DR[,"flag" := NULL] #end of fix group 2
#3, page 12 in 2011 has a column shift, need to deal with this in two pieces.
DR[source_E1=="" & final_assembly2 != "" &year==2011, flag := TRUE]
DR[flag == TRUE,`:=` (source_E1=final_assembly2,final_assembly2="",source_T1 = source_E2,source_E2="")]
DR[,"flag" := NULL]
#same page, special case
DR[year==2011 & carlines=="Routan",flag := TRUE]
DR[flag == TRUE,`:=` (source_E1=final_assembly2,final_assembly2="",source_E2 = source_E1,source_T1 = source_E2)]
DR[,"flag" := NULL]
#end of fix group 3
#4 Verano, Regal and CTS all appear to be shifted in 2017
DR[ source_E1=="" & final_assembly2 != "" &year==2017, flag :=TRUE]
DR[flag == TRUE,`:=` (source_E1=final_assembly2,final_assembly2="",source_T1 = source_E2,source_E2="")]
DR[flag == TRUE & carlines=="Verano",percent_content_other1 := "15.00% M"] # Verano has MEX content in other years
DR[,"flag" := NULL]
#5 second source is same as first source
DR[final_assembly1==final_assembly2 & final_assembly1!="", flag := TRUE]
DR[flag==TRUE,final_assembly2 := ""] # 3 lines for differen engine sizes of F150 in 2020 and 1 line for Toyota Land Cruiser made in Japn
#View(DR[flag==TRUE])
DR[,"flag" := NULL]
#done with fixes (for now)
DR[,mfg_HQ := "ROW"]
#mfg %like% "^Chrysler" not included since owned by Fiat throughout
DR[  mfg %like% "^General" | mfg=="GM LLC" | mfg %like% "^Ford" | mfg %like% "^Tesla" ,mfg_HQ := "USA" ]
DR[ mfg %like% "^Hyundai" | mfg %like% "^Kia" ,mfg_HQ := "KOR" ]
DR[ mfg %like% "^Toyota" | mfg %like% "^Mazda" | mfg %like% "Honda"| mfg %like% "^Nissan" | mfg %like% "Sukuki"  | mfg %like% "^Fuji" |  mfg %like% "^Subaru" | mfg %like% "^Mitsub",mfg_HQ := "JPN"]
DR[mfg=="PoyrscheAG",mfg := "Porsche AG"] #mfg = manufacturing group
DR[mfg %like% "^Volks" | mfg %like% "^Merc" | mfg %like% "^Porsche"| mfg %like% "^BMW" | mfg %like% "^Audi" ,mfg_HQ := "DEU" ]
# source of transmission and engine
DR[,E_US := source_E1 %like% "US" | source_E2 %like% "US"]
DR[,E_CA := source_E1 %like% "CN" | source_E2 %like% "CN" |
source_E1 %like% "CAN" | source_E2 %like% "CAN" |
(source_E1 %like% "^C"  & source_E1 %excludes% "CH")| (source_E2 %like% "^C" & source_E2 %excludes% "CH")]
#View(unique(DR[,.(source_E1,source_E2,E_US,E_CA)])[order(E_US,E_CA)])
DR[,T_US := source_T1 %like% "US" | source_T2 %like% "US"]
DR[,T_CA := source_T1 %like% "CN" | source_T2 %like% "CN" |
source_T1 %like% "CAN" | source_T2 %like% "CAN" |
(source_T1 %like% "^C"  & source_T1 %excludes% "CH")| (source_T2 %like% "^C" & source_T2 %excludes% "CH")]
#
DR[,E_MX := source_E1 %like% "MX" | source_E2 %like% "MX" | source_E1 %like% "^M" | source_E2 %like% "^M"]
DR[,T_MX := source_T1 %like% "MX" | source_T2 %like% "MX" | source_T1 %like% "^M" | source_T2 %like% "^M"]
# content shares ====
DR[,us_ca_shr := as.numeric(gsub("%","",percent_content_USA_CAN))]  # NAs by coercion (i think this is expected)
DR[is.na(us_ca_shr),table(percent_content_USA_CAN)]  # there are 52 blanks and one set of 3 values concatenated.
DR[,table(final_assembly1)]
DR[,other1_shr := as.numeric(st_left(percent_content_other1,"%"))]
DR[,other1_who := st_right(percent_content_other1,"%")]
#hand for full of data not in %
DR[percent_content_other1 %excludes% "%",other1_shr := round(100*as.numeric(substr(percent_content_other1,1,4)),0)]
DR[percent_content_other1 %excludes% "%",other1_who := substr(percent_content_other1,5,6)]
DR[other1_who %like% "^M",table(other1_who)]
DR[other1_who %like% "M",table(other1_who)]  # picks up additional cases that look like mexico
#
DR[percent_content_other2!="",.N] # 1335 obs
DR[percent_content_other2 %like% "M",table(percent_content_other2)] # these all look like Mexico
DR[,other2_shr := as.numeric(st_left(percent_content_other2,"%"))]
DR[,summary(other2_shr)]
DR[,other2_who := st_right(percent_content_other2,"%")]
DR[other2_who %like% "M",table(other2_who)]
DR[other2_who %like% "M" & is.na(other2_shr)]
#one fix for Hyundai Accent and Hyundai Accent (Manual Transmission) in 2018 where columns are messed up
DR[carlines == "Accent" & year ==2018,`:=`(other1_shr = 47,other1_who = "M",other2_who = "")]
DR[carlines == "Accent (Manual Transmission)" & year ==2018,`:=`(other1_shr = 44,other1_who = "M",other2_who = "")]
#
# Now starts encoding of assembly 1 and assembly 2
#
# fix country codes
US <- c("US","USA")
CA <- c("CN","C","CAN")
USCA <- c(CA,US,"US, CN")  #AALA doesn't do ISO...
MX <- c("M","MX")
USCAMX <- c(USCA,MX,"M, US")
# final assembly location 2
MX2 <- DR[final_assembly2 %like% "M",unique(final_assembly2)]
CA2 <- DR[final_assembly2 %like% "C" & final_assembly2 != "M (Reg\nCab)",unique(final_assembly2)]
US2 <- DR[final_assembly2 %like% "US" ,unique(final_assembly2)] #caution: %like% "U" includes UK
USCAMX2 <- union(union(US2,CA2),MX2) # union instead of c() because repeats e.g "CN, US"
#
DR[ final_assembly1 %in%  USCAMX,summary(us_ca_shr)]
DR[ final_assembly2 %in%  USCAMX2,summary(us_ca_shr)]
DR[other1_who %like% "M" &other2_who %like% "M",.N] # mex is never listed under BOTH others.
DR[other1_who %like% "M", mx_shr :=  other1_shr]
DR[final_assembly1 %in%  USCAMX,summary(mx_shr)] #
DR[final_assembly1 %in%  MX,summary(mx_shr)] #
DR[other2_who %like% "M", mx_shr :=  other2_shr]
DR[final_assembly1 %in%  MX,summary(mx_shr)] # from 40 NAs down to just 8.
DR[final_assembly2 %in%  MX2,summary(mx_shr)] # 15 NAs
# from 40 NAs down to just 8.
#
#Nafta assembly location 1 countries
DR[,ell := fcase(
final_assembly1 %in% US, "US",
final_assembly1 %in% CA, "CA",
final_assembly1 %in% MX, "MX",
final_assembly1 %ni% USCAMX, "ROW"
)]
DR[ell %in% c("CA","US","MX") & is.na(us_ca_shr),.N]  #2
DR[ell %ni% c("CA","US","MX") & is.na(us_ca_shr),.N]  #51
DR[ell %ni% c("CA","US","MX") & !is.na(us_ca_shr),.N]#2949
DR <- DR[!is.na(us_ca_shr)]# drop the missing us_ca_shr data
#
# Now starts the treatment of second assembly sites that are in NAFTA
#
# second assembly location logicals
DR[,ell2CA :=   final_assembly2 %in% CA2]
DR[,ell2US :=   final_assembly2 %in% US2]
DR[,ell2MX :=   final_assembly2 %in% MX2]
# melt in the style of a Stata reshape long. Note that the expands dataset by the number of countries : 4666*3 = 13998
D2 <- melt(DR,measure=patterns("^ell2"),value.name="add_plant",variable.name ="ell2",variable.factor = FALSE)
D2[, ell2 := gsub("ell2","",ell2)]
D2 <- D2[add_plant==TRUE] # just keep the non-primary (added) sites (122)
# drop primary assembly site (ell) and then rename the additional sites as ell, so we can append
D2[, "ell" := NULL]
setnames(D2,"ell2","ell")
# get rid of the location 2 logicals
cols_to_delete <- grep("^ell2", names(DR), value = TRUE) # removes all the ell2* columns without naming them
DR[, (cols_to_delete) := NULL]
#append the additional sites, fill in add_plant as false for the final_assembly1 sites: 4788 obs now : 4666+122
DR <- rbind(DR,D2,fill=TRUE)
DR[is.na(add_plant),add_plant := FALSE]
#
# Now starts the (complex) bounding of Mexican share (which is not a variable per se)
#
# there are two is.na(ell), that have multiple assembly countries in north america
DR[,.(meanmx = mean(mx_shr,na.rm=TRUE),meanusca = mean(us_ca_shr,na.rm=TRUE)) ,by=ell]
# none of these will catch cases where ell2 %in% c("US","CA","MX") but but ell (location 1) is not
nafta_assembly <- substitute(ell %in% c("US","CA","MX")  )
DR[eval(nafta_assembly) & is.na(other1_shr) , rem_shr := 100- us_ca_shr]
DR[eval(nafta_assembly)  & !is.na(other1_shr) & other1_who %like% "M" , rem_shr := 100- us_ca_shr]
DR[eval(nafta_assembly) & !is.na(other1_shr) &  !(other1_who %like% "M") , rem_shr := 100- us_ca_shr-other1_shr]
DR[eval(nafta_assembly), mx_shr_rem := mx_shr/rem_shr]
DR[eval(nafta_assembly),summary(mx_shr_rem)]
con.means <- DR[eval(nafta_assembly) & mx_shr_rem<1,.(mx_shr_rem_mn = mean(mx_shr_rem,na.rm=TRUE)),by=ell]
# use this later for lib
DR[eval(nafta_assembly),median(mx_shr_rem,na.rm=TRUE),by=ell]  #medians are similar
#we use the these medians to justify why we set MX at 0.5 of the remaining share
mx_md_mx <- DR[ell == "MX",median(mx_shr,na.rm=TRUE)]
DR <- merge_stata(DR,con.means,by="ell")
DR[, "stata_merge" := NULL]
# fix mexico shares, with conservative (con) and liberal (lib) assumptions
DR[,mx_shr_con := mx_shr]
DR[is.na(mx_shr), mx_shr_con :=0] # conservative guess is zero
DR[, mx_shr_lib := mx_shr_con]
# liberal assumption for mexican assembly
DR[eval(nafta_assembly) & is.na(mx_shr) & is.na(other1_shr), mx_shr_lib := (100- us_ca_shr)*mx_shr_rem_mn]
DR[eval(nafta_assembly) & is.na(mx_shr) & !is.na(other1_shr), mx_shr_lib := (100- us_ca_shr-other1_shr)*mx_shr_rem_mn]
DR[eval(nafta_assembly) & is.na(mx_shr) & mx_shr_lib>=15, mx_shr_lib := 14] #cap it at reporting threshold
# do the same for ell2? add it as an "or" in lines 130-132, see what TM thinks
it = CJ(ell = c("US","CA","MX"),assump=c("con","lib"))
sumit =function(x,y) DR[ell ==x,summary(get(paste0("mx_shr_",y)))]
sink(file="Tables_JIE_rev/nafta_shr_lib_con_rev.txt")
writeLines("Mexico shares by assembly location, conservative and then liberal")
Map(sumit,it$ell,it$assump)
DR[,nafta_shr_lib := us_ca_shr + mx_shr_lib]
DR[,nafta_shr_con := us_ca_shr + mx_shr_con]
sumit = function(x,y) DR[ell ==x,summary(get(paste0("nafta_shr_",y)))]
writeLines("Nafta shares by assembly location")
Map(sumit,it$ell,it$assump)
sink()
#
DR <- DR[,.(year,mfg,makes, carlines, type, final_assembly1,ell,final_assembly2,add_plant,us_ca_shr,mx_shr,nafta_shr_con,nafta_shr_lib,mfg_HQ)]
saveRDS(DR,"Data/RDS_JIE_rev/AALA_rev.rds")
library(HeadR)
rm(list=ls())
#
calib.years <- 2011:2019
#
L2norm <- function(u,v) sqrt(sum((u-v)^2))
CAMUS = c("CA","MX","US")
MEX_con_lib <- "con" # either con or lib assumption on Mexican share
#
DR <- readRDS("Data/RDS_JIE_rev/AALA_rev.rds")[year %in% calib.years]  # data prepared by R_JIE_rev/AALA_clean.R
#
# Choose the conservative or liberal going forward, and compute data density, also load tau index
if(MEX_con_lib=="con")  DR[,nafta_shr := nafta_shr_con] else DR[,nafta_shr := nafta_shr_lib]
DR[,summary(nafta_shr)]
DR[,typeA := fifelse(type %like% "Truck","Truck","Car/MPV")]
DR[,ellA := fcase(ell == "CA","Canada",ell=="US","USA",ell=="MX","Mexico")]
#
#unique carlines
iqr <- function(x){IQR(x)}
DRc <- dcast(DR[ell %in% CAMUS],ellA~typeA,value.var = list("carlines","nafta_shr","nafta_shr"),fun = list(uniqueN,median,iqr))
#
# Bring in tau
DT <- readRDS("Data/RDS_JIE_rev/tau_index_DRF.rds")
sink(file="Tables_JIE_rev/tauD_count.txt")
DT[!is.na(tauD),.N]
sink()
setnames(DT,"tauD","tau_index")
#unique models
DTc <- dcast(DT,V_iso_o~HS_head,value.var = list("V_id","tau_index"),fun = list(uniqueN,median))
#B for both lambda and tau:
DB <- cbind(DRc,DTc)
#length = carline-years or model-years
DB[,out := texout(.(ellA,`carlines_uniqueN_Car/MPV`,`nafta_shr_median_Car/MPV`,
V_id_uniqueN_8703,tau_index_median_8703,carlines_uniqueN_Truck,nafta_shr_median_Truck,
V_id_uniqueN_8704,tau_index_median_8704))]
writeLines(DB$out,"Tables_JIE_rev/AALA_IHS_table.tex")
# Figure 8
library(HeadR)
library(latex2exp)
rm(list=ls())
# make a directory "Data/RDS_JIE_rev/Params4" for the parameters (if it does not already exist)
if (file.exists("Data/RDS_JIE_rev/Params4")) {
print("Directory exists")
} else {
dir.create("Data/RDS_JIE_rev/Params4",recursive = FALSE, showWarnings = TRUE)
print("Directory did not exist so  created it")
}
source("R_JIE_rev/AALA_calibration_functions.R") #
#
calib.years <- 2011:2019
L2norm <- function(u,v) sqrt(sum((u-v)^2))
CAMUS = c("CA","MX","US")
MEX_con_lib <- "con" # either con or lib assumption on Mexican share
dist.alpha <- "Beta" #
alpha.base <- 0.15
theta.base <- 4
params = list(theta=theta.base,mu=0.1,sigma=0.1,RCR=0.625,tau=1.025,alpha.lo=0,alpha.hi=0,alpha.a =1e7,alpha.b=1e7)
RCR = 100*params$RCR
#
DR = readRDS("Data/RDS_JIE_rev/AALA_rev.rds")[year %in% calib.years]   # data prepared by AALA_clean.R
#
#
# Choose the conservative or liberal going forward, and compute data density
if(MEX_con_lib=="con")  DR[,nafta_shr := nafta_shr_con] else DR[,nafta_shr := nafta_shr_lib]
DR[,summary(nafta_shr)]
lambda_data_d = DR[!is.na(nafta_shr) & ell %in% CAMUS, density(nafta_shr)]
Num.obs = DR[!is.na(nafta_shr)& ell %in% CAMUS,.N]  #1704
#
# Plot : model of density of lambda with only delta heterogeneity, including data density ====
# pedagogical: shows density hole and spike problems
# do it for alpha = 0, so that we have a minimal version
#
# simulation
set.seed(140422)
params = list(theta=theta.base,mu=0,sigma=0.2,RCR=0.625,tau=1.1,alpha.lo=0,alpha.hi=0,alpha.a =1e7,alpha.b=1e7) # pseudo calibrated
sim_out <- sim_lambda(RCR=params$RCR,theta=params$theta,mu=params$mu,sigma=params$sigma,
alpha.lo=params$alpha.lo,alpha.hi=params$alpha.hi,alpha.a=params$alpha.a,alpha.b=params$alpha.b,
tau_data=params$tau,N=Num.obs*20)
# densities from the simulated model
lambda_sim = 100*sim_out$lambda_model
lambda_sim_d = density(lambda_sim)
lambda_U_d = density(sim_out$lambda_U*100) # density for unconstrained
#
# compute a number of ranges for the graph
x_rng = seq(0.01,99.9,by=0.01)
y_rng = pdf_U(x_rng,theta=params$theta,mu=params$mu,sigma=params$sigma)
ycap = 0.065
ymax = max(c(lambda_data_d$y,lambda_U_d$y))
ymax = 1.2*min(ymax,ycap)
eps =0.5
lambda.RCR <- lambda_RCR(RCR=params$RCR,alpha=0) # firm-specific if alpha het, not here.
RCR <- 100*lambda.RCR
brk = ymax*0.85
gap = 0.0015
#
#  plot the model + lib + con data ====
pdf("Plots_JIE_rev/AALA_calib/AALA_calib_model_data.pdf",7.5,4)
par(mar=c(4,4,0.5,0.75)+0.1 )
# empty plot
plot(c(0,100),c(0,0),col="black",lty="dotted",main ="",xlab="Nafta cost share (%)",
ylab="Density",xlim=c(0,100),xaxs="i",ylim=c(0.0,ymax),type="n",xaxt="n")
# data and RCR
DR[!is.na(nafta_shr_con) & ell %in% CAMUS,lines(density(nafta_shr_con),col="black",lwd=2)]
# unconstrained lambda_U
lines(x_rng,y_rng,type="l",col="orange",lwd=3)
# model (basic, delta het only, alpha = 0)
delta_star = delta.star(lambda_R=lambda.RCR,tau=params$tau,theta=params$theta)
lambda_star = 100*lambda_U(delta_star,params$theta)
xaxmarks =c(0,lambda_star,25,50,RCR,75,85,100)
axis(side = 1, at=xaxmarks,labels=c(0,TeX("$\\lambda_U(\\delta^*)$"),25,50,TeX(sprintf(r'($\lambda_R = %.1f $)',RCR)),75,85,100))
# non-compliers density
polygon(c(x_rng[x_rng<lambda_star],lambda_star),c(y_rng[x_rng<lambda_star],0),col=adjustcolor("forestgreen",0.25),border=NA)
# compliers unconstrained density
polygon(c(RCR,x_rng[x_rng>RCR]),c(0,y_rng[x_rng>RCR]),col=adjustcolor("forestgreen",0.25),border=NA)
lines(x_rng[x_rng<lambda_star],y_rng[x_rng<lambda_star],col="forestgreen",lwd=1)
segments(lambda_star,0,lambda_star,max(pdf_U(lambda_star,theta=params$theta,mu=params$mu,sig=params$sig)),col="forestgreen",lwd=1)
segments(lambda_star,0,RCR,0,col="forestgreen",lwd=1)
# complier constrained
polygon(c(RCR-eps,RCR+eps,RCR+eps,RCR-eps),c(ymax*0.95,ymax*0.95,brk,brk+gap),col=adjustcolor("forestgreen",0.25),border = NULL)
polygon(c(RCR-eps,RCR+eps,RCR+eps,RCR-eps),c(brk,brk-gap,0,0),col=adjustcolor("forestgreen",0.25))
text(RCR,ymax*0.95,sprintf("Comply con.= %.2f",round(sim_out$comply_frac,2)),pos=4,cex=0.8)
lines(x_rng[x_rng>RCR],y_rng[x_rng>RCR],col="forestgreen",lwd=1)
# text(17.5,ymax/3,"Non-compliers",pos=2,cex=0.8,adj=0)
# arrows(17,ymax/3,lambda_star-3*eps, 0.6* eps/100,length=0.07)
text(10,ymax/3,"Non-compliers",pos=3,cex=0.8,adj=0)
arrows(10,ymax/3,lambda_star-3*eps, 0.6* eps/100,length=0.07)
text(65,0.005,"Comply uncon.",pos=4,cex=0.8)
#arrows(75,0.007,RCR+8*eps,0.005,length=0.07)
#legend("topleft",lwd=c(2,2,2),col=c("blue","black","orange","forestgreen"),legend=c("Data (con)","Data (lib)",TeX("Model (no ROO)"),"Model (with ROO)"),bty="n")
legend("topleft",lwd=c(2,2,2),col=c("black","orange","forestgreen"),legend=c("Data",TeX("Model (no ROO)"),"Model (with ROO)"),bty="n")
legend("topright",legend=c(TeX(sprintf(r'($\theta = %.1f$)', params$theta)),
TeX(sprintf(r'($\mu = %.2f$)', params$mu)),
TeX(sprintf(r'($\sigma = %.2f$)', params$sigma)),
TeX(sprintf(r'($\tau = %.2f$)', params$tau)),
TeX(sprintf(r'($\alpha = %.0f$)', 0))),
bty="n")
dev.off()
library(tictoc)
library(HeadR)
library(latex2exp)
library(parallel)
library(beepr)
rm(list=ls())
source("R_JIE_rev/AALA_calibration_functions.R") #
calib.years <- 2011:2019
gen.figs <- TRUE # set to TRUE to generate  density and Laffer curves
numpar <- 4 # number of parameters to brute force  (grid search) over
L2norm <- function(u,v) sqrt(sum((u-v)^2))
CAMUS = c("CA","MX","US")
MEX_con_lib <- "con" # either con or lib assumption on Mexican share
dist.alpha <- "Beta" #
alpha.base <- 0.15
theta.base <- 4
params = list(RCR=0.625)
RCR = 100*params$RCR
DR <- readRDS("Data/RDS_JIE_rev/AALA_rev.rds")[year %in% calib.years]  # data prepared by AALA_clean.R, with many fixes
# Choose the conservative or liberal going forward, and compute data density, also load tau index
if(MEX_con_lib=="con")  DR[,nafta_shr := nafta_shr_con] else DR[,nafta_shr := nafta_shr_lib]
DR[,summary(nafta_shr)]
lambda_data_d = DR[!is.na(nafta_shr) & ell %in% CAMUS, density(nafta_shr)]
Num.obs = DR[!is.na(nafta_shr)& ell %in% CAMUS,.N]  #1704
DD <- data.table(x=lambda_data_d$x,y=lambda_data_d$y)
DD[,x_rnd := round(x)]
DD <- DD[x_rnd %between% c(0,100),.(den_data = mean(y)),by=x_rnd]
#
DC <- readRDS("Data/RDS_JIE_rev/tau_index_DRF.rds") #
#
params = list(theta=theta.base,mu=0.0,sigma=0.0,RCR=0.625,tau=DC$tau_index,alpha=alpha.base,conc.err=1e10)
params$tau <- data.table(tau=DC$tauD,tauQ=1)
mu.grid <- seq(from=-0.1,to=0.25,by=0.01) # 36 values
sigma.grid <- seq(from=0.0,to=0.25,by=0.01) #26
dist.alpha <- "Beta"
alphacon.grid <- c(1,1.25,1.5,1.75,2,2.25,2.5,3:20)
errcon.grid <- c(2:25) #24
#
param.grid <- CJ(sigma=sigma.grid,alphacon =alphacon.grid,errcon =errcon.grid) #cartesian product of params (other than mu)
n.vals = dim(param.grid)[1]
k = dim(param.grid)[2]+1  # number of parameters to brute force over
#
test <- brute_force_4par(0) #
library(tictoc)
library(HeadR)
library(latex2exp)
library(parallel)
library(beepr)
rm(list=ls())
source("R_JIE_rev/AALA_calibration_functions.R") #
#
calib.years <- 2011:2019
gen.figs <- TRUE # set to TRUE to generate  density and Laffer curves
numpar <- 4 # number of parameters to brute force  (grid search) over
#
L2norm <- function(u,v) sqrt(sum((u-v)^2))
CAMUS = c("CA","MX","US")
MEX_con_lib <- "con" # either con or lib assumption on Mexican share
dist.alpha <- "Beta" #
alpha.base <- 0.15
theta.base <- 4
params = list(RCR=0.625)
RCR = 100*params$RCR
#
DR <- readRDS("Data/RDS_JIE_rev/AALA_rev.rds")[year %in% calib.years]  # data prepared by AALA_clean.R, with many fixes
#
# Choose the conservative or liberal going forward, and compute data density, also load tau index
if(MEX_con_lib=="con")  DR[,nafta_shr := nafta_shr_con] else DR[,nafta_shr := nafta_shr_lib]
DR[,summary(nafta_shr)]
lambda_data_d = DR[!is.na(nafta_shr) & ell %in% CAMUS, density(nafta_shr)]
Num.obs = DR[!is.na(nafta_shr)& ell %in% CAMUS,.N]  #1704
DD <- data.table(x=lambda_data_d$x,y=lambda_data_d$y)
DD[,x_rnd := round(x)]
DD <- DD[x_rnd %between% c(0,100),.(den_data = mean(y)),by=x_rnd]
#
DC <- readRDS("Data/RDS_JIE_rev/tau_index_DRF.rds") #
#
params = list(theta=theta.base,mu=0.0,sigma=0.0,RCR=0.625,tau=DC$tau_index,alpha=alpha.base,conc.err=1e10)
params$tau <- data.table(tau=DC$tauD,tauQ=1)
#
# Optimization with 4 params: mu sigma alpha-conc err-conc ====
#
mu.grid <- seq(from=-0.1,to=0.25,by=0.01) # 36 values
sigma.grid <- seq(from=0.0,to=0.25,by=0.01) #26
dist.alpha <- "Beta"
alphacon.grid <- c(1,1.25,1.5,1.75,2,2.25,2.5,3:20)
errcon.grid <- c(2:25) #24
#
param.grid <- CJ(sigma=sigma.grid,alphacon =alphacon.grid,errcon =errcon.grid) #cartesian product of params (other than mu)
n.vals = dim(param.grid)[1]
k = dim(param.grid)[2]+1  # number of parameters to brute force over
#
# test <- brute_force_4par(0) # check it works for mu= 0 before launching full search
tic()
DT.results <- mclapply(mu.grid,brute_force_4par,mc.cores = detectCores()-2) |> rbindlist()
library(tictoc)
library(HeadR)
library(latex2exp)
library(parallel)
library(beepr)
rm(list=ls())
source("R_JIE_rev/AALA_calibration_functions.R") #
#
calib.years <- 2011:2019
gen.figs <- TRUE # set to TRUE to generate  density and Laffer curves
numpar <- 4 # number of parameters to brute force  (grid search) over
#
L2norm <- function(u,v) sqrt(sum((u-v)^2))
CAMUS = c("CA","MX","US")
MEX_con_lib <- "con" # either con or lib assumption on Mexican share
dist.alpha <- "Beta" #
alpha.base <- 0.15
theta.base <- 4
params = list(RCR=0.625)
RCR = 100*params$RCR
#
DR <- readRDS("Data/RDS_JIE_rev/AALA_rev.rds")[year %in% calib.years]  # data prepared by AALA_clean.R, with many fixes
#
# Choose the conservative or liberal going forward, and compute data density, also load tau index
if(MEX_con_lib=="con")  DR[,nafta_shr := nafta_shr_con] else DR[,nafta_shr := nafta_shr_lib]
DR[,summary(nafta_shr)]
lambda_data_d = DR[!is.na(nafta_shr) & ell %in% CAMUS, density(nafta_shr)]
Num.obs = DR[!is.na(nafta_shr)& ell %in% CAMUS,.N]  #1704
DD <- data.table(x=lambda_data_d$x,y=lambda_data_d$y)
DD[,x_rnd := round(x)]
DD <- DD[x_rnd %between% c(0,100),.(den_data = mean(y)),by=x_rnd]
#
DC <- readRDS("Data/RDS_JIE_rev/tau_index_DRF.rds") #
#
params = list(theta=theta.base,mu=0.0,sigma=0.0,RCR=0.625,tau=DC$tau_index,alpha=alpha.base,conc.err=1e10)
params$tau <- data.table(tau=DC$tauD,tauQ=1)
#
# Optimization with 4 params: mu sigma alpha-conc err-conc ====
#
mu.grid <- seq(from=-0.1,to=0.25,by=0.01) # 36 values
sigma.grid <- seq(from=0.0,to=0.25,by=0.01) #26
dist.alpha <- "Beta"
alphacon.grid <- c(1,1.25,1.5,1.75,2,2.25,2.5,3:20)
errcon.grid <- c(2:25) #24
#
param.grid <- CJ(sigma=sigma.grid,alphacon =alphacon.grid,errcon =errcon.grid) #cartesian product of params (other than mu)
n.vals = dim(param.grid)[1]
k = dim(param.grid)[2]+1  # number of parameters to brute force over
#
# test <- brute_force_4par(0) # check it works for mu= 0 before launching full search
tic()
DT.results <- mclapply(mu.grid,brute_force_4par,mc.cores = detectCores()-2) |> rbindlist()
?mclapply
detectCores()
# DT.results <- mclapply(mu.grid,brute_force_4par,mc.cores = detectCores()-2) |> rbindlist()
cl <- makeCluster(detectCores() - 2)
DT.results <- parLapply(mu.grid,brute_force_4par,cl) |> rbindlist()
DT.results <- parLapply(cl, mu.grid, brute_force_4par) |> rbindlist()
# DT.results <- mclapply(mu.grid,brute_force_4par,mc.cores = detectCores()-2) |> rbindlist()
# cl <- makeCluster(detectCores() - 2)
# DT.results <- parLapply(cl, mu.grid, brute_force_4par) |> rbindlist()
DT.results <- mclapply(mu.grid,brute_force_4par,mc.cores = 1) |> rbindlist()
library(tictoc)
library(HeadR)
library(latex2exp)
library(parallel)
library(beepr)
rm(list=ls())
source("R_JIE_rev/AALA_calibration_functions.R") #
#
calib.years <- 2011:2019
gen.figs <- TRUE # set to TRUE to generate  density and Laffer curves
numpar <- 4 # number of parameters to brute force  (grid search) over
#
L2norm <- function(u,v) sqrt(sum((u-v)^2))
CAMUS = c("CA","MX","US")
MEX_con_lib <- "con" # either con or lib assumption on Mexican share
dist.alpha <- "Beta" #
alpha.base <- 0.15
theta.base <- 4
params = list(RCR=0.625)
RCR = 100*params$RCR
#
DR <- readRDS("Data/RDS_JIE_rev/AALA_rev.rds")[year %in% calib.years]  # data prepared by AALA_clean.R, with many fixes
#
# Choose the conservative or liberal going forward, and compute data density, also load tau index
if(MEX_con_lib=="con")  DR[,nafta_shr := nafta_shr_con] else DR[,nafta_shr := nafta_shr_lib]
DR[,summary(nafta_shr)]
lambda_data_d = DR[!is.na(nafta_shr) & ell %in% CAMUS, density(nafta_shr)]
Num.obs = DR[!is.na(nafta_shr)& ell %in% CAMUS,.N]  #1704
DD <- data.table(x=lambda_data_d$x,y=lambda_data_d$y)
DD[,x_rnd := round(x)]
DD <- DD[x_rnd %between% c(0,100),.(den_data = mean(y)),by=x_rnd]
#
DC <- readRDS("Data/RDS_JIE_rev/tau_index_DRF.rds") #
#
params = list(theta=theta.base,mu=0.0,sigma=0.0,RCR=0.625,tau=DC$tau_index,alpha=alpha.base,conc.err=1e10)
params$tau <- data.table(tau=DC$tauD,tauQ=1)
#
# Optimization with 4 params: mu sigma alpha-conc err-conc ====
#
mu.grid <- seq(from=-0.1,to=0.25,by=0.01) # 36 values
sigma.grid <- seq(from=0.0,to=0.25,by=0.01) #26
dist.alpha <- "Beta"
alphacon.grid <- c(1,1.25,1.5,1.75,2,2.25,2.5,3:20)
errcon.grid <- c(2:25) #24
#
param.grid <- CJ(sigma=sigma.grid,alphacon =alphacon.grid,errcon =errcon.grid) #cartesian product of params (other than mu)
n.vals = dim(param.grid)[1]
k = dim(param.grid)[2]+1  # number of parameters to brute force over
#
# test <- brute_force_4par(0) # check it works for mu= 0 before launching full search
tic()
# DT.results <- mclapply(mu.grid,brute_force_4par,mc.cores = detectCores()-2) |> rbindlist()
# cl <- makeCluster(detectCores() - 2)
# DT.results <- parLapply(cl, mu.grid, brute_force_4par) |> rbindlist()
DT.results <- mclapply(mu.grid,brute_force_4par,mc.cores = 1) |> rbindlist()
